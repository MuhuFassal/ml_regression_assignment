Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it
represent?
Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.
Q3. When is it more appropriate to use adjusted R-squared?
Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics
calculated, and what do they represent?
Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in
regression analysis.
Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is
it more appropriate to use?
Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an
example to illustrate.
Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best
choice for regression analysis.
Q9. You are comparing the performance of two regression models using different evaluation metrics.
Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better
performer, and why? Are there any limitations to your choice of metric?
Q10. You are comparing the performance of two regularized linear models using different types of
regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B
uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the
better performer, and why? Are there any trade-offs or limitations to your choice of regularization
method?



### Q1. Concept of R-squared

**R-squared**, or the coefficient of determination, is a statistical measure in linear regression that represents the proportion of the variance in the dependent variable that is predictable from the independent variables.

**Calculation**: It is calculated as:
\[ R^2 = 1 - \frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}} \]
where:
- \(\text{SS}_{\text{res}}\) is the sum of the squared residuals (errors), i.e., \(\sum (y_i - \hat{y}_i)^2\).
- \(\text{SS}_{\text{tot}}\) is the total sum of squares, i.e., \(\sum (y_i - \bar{y})^2\), with \(y_i\) being the actual value and \(\bar{y}\) the mean of the observed values.

**Representation**: R-squared represents how well the independent variables explain the variability of the dependent variable. A value of 1 indicates that the model explains all the variability of the response data around its mean, while a value of 0 indicates that the model explains none of the variability.

### Q2. Adjusted R-squared

**Adjusted R-squared** is a modified version of R-squared that adjusts for the number of predictors in the model. It accounts for the fact that adding more variables to a model will always increase R-squared, regardless of whether those variables are meaningful.

**Calculation**: It is calculated as:
\[ \text{Adjusted } R^2 = 1 - \left( \frac{(1 - R^2)(n - 1)}{n - p - 1} \right) \]
where:
- \(n\) is the number of observations.
- \(p\) is the number of predictors (independent variables).

**Difference**: While R-squared can increase with more predictors (even if they are not useful), Adjusted R-squared will only increase if the new predictor improves the model more than would be expected by chance.

### Q3. When to Use Adjusted R-squared

**Adjusted R-squared** is more appropriate when comparing models with different numbers of predictors. It provides a more accurate measure of model performance by penalizing excessive use of predictors and therefore helps in evaluating models with multiple predictors.

### Q4. RMSE, MSE, and MAE

- **Mean Squared Error (MSE)**: Measures the average squared difference between observed and predicted values. It is calculated as:
  \[ \text{MSE} = \frac{1}{n} \sum (y_i - \hat{y}_i)^2 \]
  where \(n\) is the number of observations.

- **Root Mean Squared Error (RMSE)**: The square root of MSE, providing error in the same units as the target variable. It is calculated as:
  \[ \text{RMSE} = \sqrt{\text{MSE}} \]

- **Mean Absolute Error (MAE)**: Measures the average absolute difference between observed and predicted values. It is calculated as:
  \[ \text{MAE} = \frac{1}{n} \sum |y_i - \hat{y}_i| \]

**Representation**: These metrics represent the magnitude of the errors in predictions. MSE and RMSE penalize larger errors more heavily due to squaring, while MAE treats all errors equally.

### Q5. Advantages and Disadvantages

- **RMSE**:
  - **Advantage**: Provides a measure of error in the same units as the target variable; sensitive to large errors.
  - **Disadvantage**: Can be disproportionately affected by outliers due to squaring.

- **MSE**:
  - **Advantage**: Provides a clear mathematical measure of average error magnitude; sensitive to large errors.
  - **Disadvantage**: Units are squared, which can make interpretation less intuitive; sensitive to outliers.

- **MAE**:
  - **Advantage**: Provides a clear and interpretable measure of average error; less sensitive to outliers compared to MSE and RMSE.
  - **Disadvantage**: Does not penalize large errors as strongly as RMSE.

### Q6. Lasso vs. Ridge Regularization

- **Lasso (Least Absolute Shrinkage and Selection Operator)**: Adds a penalty equal to the absolute value of the magnitude of coefficients. It encourages sparsity, meaning it can drive some coefficients to zero, effectively selecting a simpler model.
  \[ \text{Lasso penalty} = \lambda \sum_{j} |\beta_j| \]

- **Ridge Regularization**: Adds a penalty equal to the square of the magnitude of coefficients. It tends to shrink coefficients but rarely sets them to zero, thus maintaining all features in the model but with reduced impact.
  \[ \text{Ridge penalty} = \lambda \sum_{j} \beta_j^2 \]

**Appropriate Use**:
- **Lasso**: When you suspect that only a subset of the predictors are relevant.
- **Ridge**: When you believe all predictors contribute to the outcome but want to control their impact.

### Q7. Regularized Linear Models and Overfitting

**Regularized models** help prevent overfitting by penalizing large coefficients and thus constraining the complexity of the model. For example, in Ridge regression, the penalty term reduces the size of coefficients, which can prevent the model from fitting the noise in the training data.

**Example**: Suppose you have a polynomial regression model with a high-degree polynomial. This model may fit the training data perfectly but fail on new data due to overfitting. By applying Ridge or Lasso regularization, the model coefficients are penalized, leading to a simpler model that generalizes better to unseen data.

### Q8. Limitations of Regularized Linear Models

- **Ridge**: Does not perform feature selection; all predictors remain in the model, potentially leading to less interpretability.
- **Lasso**: Can be too aggressive in setting coefficients to zero, which might lead to loss of important information if not carefully tuned.
- **Elastic Net**: Combines penalties from both Ridge and Lasso, providing a balance but requiring careful tuning of both parameters.

**When Not Ideal**:
- When there is a need for interpretability and feature selection (Lasso is better in this case).
- When the relationship between predictors and response is not well-captured by linear assumptions.

### Q9. Comparing Models with RMSE and MAE

- **Model A (RMSE = 10)**: Penalizes larger errors more heavily.
- **Model B (MAE = 8)**: Treats all errors equally.

**Choice**:
- **MAE** is generally preferred when you want to minimize the impact of outliers and have a clear interpretation of average error. If the goal is to have a model that performs well on average but is less influenced by outliers, Model B might be better.
- **Limitations**: Relying solely on one metric may not give a full picture of model performance, particularly if outliers or large errors are of significant concern.

### Q10. Comparing Regularized Models

- **Ridge (λ = 0.1)**: Will provide a smoother model by shrinking coefficients but keeping all features.
- **Lasso (λ = 0.5)**: Will potentially zero out some coefficients, leading to a more sparse model with feature selection.

**Choice**:
- If feature selection is important and you suspect many features are irrelevant, **Model B (Lasso)** might be preferable.
- If all features are believed to contribute to the prediction and you seek to reduce the impact of each feature rather than eliminate any, **Model A (Ridge)** might be better.

**Trade-offs**:
- Lasso may discard useful features if not tuned properly.
- Ridge maintains all features but might not address multicollinearity as effectively as Lasso.
